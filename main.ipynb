{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will use a collection of SMS spam messages as data.\n",
    "# get data at https://archive.ics.uci.edu/ml/datasets/sms+spam+collection\n",
    "import pandas as pd\n",
    "df = pd.read_table('data/SMSSpamCollection.tsv', sep='\\t', header=None,\n",
    "\t\t\t\t   names=['label', 'message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "     label                                            message\n0      ham  Go until jurong point, crazy.. Available only ...\n1      ham                      Ok lar... Joking wif u oni...\n2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n3      ham  U dun say so early hor... U c already then say...\n4      ham  Nah I don't think he goes to usf, he lives aro...\n...    ...                                                ...\n5567  spam  This is the 2nd time we have tried 2 contact u...\n5568   ham               Will ü b going to esplanade fr home?\n5569   ham  Pity, * was in mood for that. So...any other s...\n5570   ham  The guy did some bitching but I acted like i'd...\n5571   ham                         Rofl. Its true to its name\n\n[5572 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>message</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ham</td>\n      <td>Go until jurong point, crazy.. Available only ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ham</td>\n      <td>Ok lar... Joking wif u oni...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>spam</td>\n      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ham</td>\n      <td>U dun say so early hor... U c already then say...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ham</td>\n      <td>Nah I don't think he goes to usf, he lives aro...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5567</th>\n      <td>spam</td>\n      <td>This is the 2nd time we have tried 2 contact u...</td>\n    </tr>\n    <tr>\n      <th>5568</th>\n      <td>ham</td>\n      <td>Will ü b going to esplanade fr home?</td>\n    </tr>\n    <tr>\n      <th>5569</th>\n      <td>ham</td>\n      <td>Pity, * was in mood for that. So...any other s...</td>\n    </tr>\n    <tr>\n      <th>5570</th>\n      <td>ham</td>\n      <td>The guy did some bitching but I acted like i'd...</td>\n    </tr>\n    <tr>\n      <th>5571</th>\n      <td>ham</td>\n      <td>Rofl. Its true to its name</td>\n    </tr>\n  </tbody>\n</table>\n<p>5572 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Looks like that\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/ao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## nltk is a text-processing library\n",
    "import nltk\n",
    "# it has models for different languages, here we download one\n",
    "nltk.download('punkt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "## CountVectorizer counts entries of every token in the collection\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def extract_features(messages: pd.Series, vocabulary=None):\n",
    "\tstemmer = PorterStemmer()\n",
    "\n",
    "\t## Let's clean messages from non-text characters\n",
    "\tmessages = messages.map(lambda x: x.lower().replace('[^\\w\\s]', ''))\n",
    "\t## transform free text into a collection of words(list of strings)\n",
    "\tmessages = messages.apply(nltk.word_tokenize)\n",
    "\t## the idea is that spam sms has high likelihood for certain words. We use\n",
    "\t## stemming to exclude different word forms and count only word stems\n",
    "\tmessages = messages.apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "\tmessages = messages.apply(lambda x: ' '.join(x))\n",
    "\n",
    "\tparams = {}\n",
    "\tif vocabulary:\n",
    "\t\tparams['vocabulary'] = vocabulary\n",
    "\t## CountVectorizer counts entries of every token in the collection\n",
    "\tcount_vect = CountVectorizer(**params)\n",
    "\tcounts = count_vect.fit_transform(messages)\n",
    "\n",
    "\treturn count_vect, counts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "## We need to transform categories into machine-readable values(probabilities)\n",
    "df['label'] = df.label.map({'ham': 0, 'spam': 1})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "count_vect, counts = extract_features(df['message'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['board', 'boat', 'boatin', 'bob', 'bodi', 'boggi', 'bognor', 'bold', 'bold2', 'bollox', 'boltblu', 'bomb', 'bone', 'bong', 'bonu', 'boo', 'boob', 'book', 'bookedth', 'bookmark']\n",
      "      0     1     2     3     4     5     6     7     8     9     ...  7444  \\\n",
      "0        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "1        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "2        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "3        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "4        0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
      "5567     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "5568     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "5569     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "5570     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "5571     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "\n",
      "      7445  7446  7447  7448  7449  7450  7451  7452  7453  \n",
      "0        0     0     0     0     0     0     0     0     0  \n",
      "1        0     0     0     0     0     0     0     0     0  \n",
      "2        0     0     0     0     0     0     0     0     0  \n",
      "3        0     0     0     0     0     0     0     0     0  \n",
      "4        0     0     0     0     0     0     0     0     0  \n",
      "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
      "5567     0     0     0     0     0     0     0     0     0  \n",
      "5568     0     0     0     0     0     0     0     0     0  \n",
      "5569     0     0     0     0     0     0     0     0     0  \n",
      "5570     0     0     0     0     0     0     0     0     0  \n",
      "5571     0     0     0     0     0     0     0     0     0  \n",
      "\n",
      "[5572 rows x 7454 columns]\n"
     ]
    }
   ],
   "source": [
    "## Inside is the list of all stems and their counts\n",
    "print(count_vect.get_feature_names()[1500:1520])\n",
    "print(pd.DataFrame(counts.toarray()))\n",
    "ddd = pd.DataFrame(counts.toarray())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "## we split some part of our dataset to validate trained model later\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts, df['label'], test_size=0.1, random_state=69)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "model = MultinomialNB().fit(X_train, y_train)\n",
    "# model = SVC(kernel='polynomial').fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.985663082437276\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "## it better be close to 1 as possible, means we trained model well\n",
    "print(np.mean(predicted == y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[479   3]\n",
      " [  5  71]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "## show number of false positives and negatives\n",
    "conf_mat = confusion_matrix(y_test, predicted)\n",
    "print(conf_mat)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.9896694214876033\n",
      "recall: 0.9937759336099585\n",
      "f1 score: 0.9466666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "tp = conf_mat[0][0]\n",
    "fp = conf_mat[1][0]\n",
    "fn = conf_mat[0][1]\n",
    "print(f'precision: {tp/ (tp + fp)}')\n",
    "print(f'recall: {tp/ (tp + fn)}')\n",
    "print(f'f1 score: {f1_score(y_test, predicted)}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "### Let's experiment with random string outside the dataset!\n",
    "text_to_check = [\n",
    "\t'I bet you win tonight haha',\n",
    "\t'Signup via the link and receive a free bonus! http://bit.ly/XdgfA',\n",
    "]\n",
    "new_count_vect, new_counts = extract_features(\n",
    "\tpd.Series(text_to_check), count_vect.get_feature_names())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are model's predictions for strings:\n"
     ]
    },
    {
     "data": {
      "text/plain": "[(False, 'I bet you win tonight haha'),\n (True, 'Signup via the link and receive a free bonus! http://bit.ly/XdgfA')]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('There are model\\'s predictions for strings:')\n",
    "list(zip(map(bool, model.predict(new_counts)), text_to_check))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}